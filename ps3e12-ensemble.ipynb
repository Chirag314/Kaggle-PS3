{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Reference Notebook \nhttps://www.kaggle.com/code/tetsutani/ps3e12-self-supervised-tabnet-using-optuna-0-896","metadata":{}},{"cell_type":"code","source":"# Import libraries for Tabnet\nimport torch\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2023-04-14T06:34:57.749971Z","iopub.execute_input":"2023-04-14T06:34:57.750360Z","iopub.status.idle":"2023-04-14T06:34:59.601515Z","shell.execute_reply.started":"2023-04-14T06:34:57.750330Z","shell.execute_reply":"2023-04-14T06:34:59.600232Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install pytorch-tabnet","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-04-14T06:35:02.675332Z","iopub.execute_input":"2023-04-14T06:35:02.676484Z","iopub.status.idle":"2023-04-14T06:35:16.288633Z","shell.execute_reply.started":"2023-04-14T06:35:02.676436Z","shell.execute_reply":"2023-04-14T06:35:16.287367Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nCollecting pytorch-tabnet\n  Downloading pytorch_tabnet-4.0-py3-none-any.whl (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.7.3)\nRequirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (4.64.1)\nRequirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.0.2)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.21.6)\nRequirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.12.0+cpu)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.1.1)\nInstalling collected packages: pytorch-tabnet\nSuccessfully installed pytorch-tabnet-4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# Import libraries for Tabnet\nfrom pytorch_tabnet.pretraining import TabNetPretrainer\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nfrom pytorch_tabnet.tab_model import TabNetClassifier","metadata":{"execution":{"iopub.status.busy":"2023-04-14T06:35:41.742673Z","iopub.execute_input":"2023-04-14T06:35:41.743127Z","iopub.status.idle":"2023-04-14T06:35:42.160959Z","shell.execute_reply.started":"2023-04-14T06:35:41.743090Z","shell.execute_reply":"2023-04-14T06:35:42.159824Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport os\nfrom copy import deepcopy\nfrom functools import partial\n\n# Import sklearn classes for model selection, cross validation, and performance evaluation\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold, GroupKFold, GroupShuffleSplit, RepeatedStratifiedKFold\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nfrom category_encoders import OneHotEncoder\n\n# Import libraries for Hypertuning\nimport optuna\noptuna.logging.set_verbosity(optuna.logging.ERROR)\n\n# Import libraries for gradient boosting\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom catboost import CatBoost, CatBoostRegressor, CatBoostClassifier\nfrom catboost import Pool\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T06:35:46.606720Z","iopub.execute_input":"2023-04-14T06:35:46.607189Z","iopub.status.idle":"2023-04-14T06:35:48.774417Z","shell.execute_reply.started":"2023-04-14T06:35:46.607151Z","shell.execute_reply":"2023-04-14T06:35:48.772305Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"### Load data","metadata":{}},{"cell_type":"code","source":"filepath = '/kaggle/input/playground-series-s3e12'\n\ndf_train = pd.read_csv(os.path.join(filepath, 'train.csv'), index_col=[0])\ndf_test = pd.read_csv(os.path.join(filepath, 'test.csv'), index_col=[0])\noriginal = pd.read_csv('/kaggle/input/kidney-stone-prediction-based-on-urine-analysis/kindey stone urine analysis.csv')\n\ndf_train['is_generated'] = 1\ndf_test['is_generated'] = 1\noriginal['is_generated'] = 0\n\noriginal = original.reset_index()\noriginal['id'] = original['index'] + df_test.index[-1] + 1\noriginal = original.drop(columns = ['index']).set_index('id')\n\ntarget_col = 'target'","metadata":{"execution":{"iopub.status.busy":"2023-04-14T06:35:53.307190Z","iopub.execute_input":"2023-04-14T06:35:53.309096Z","iopub.status.idle":"2023-04-14T06:35:53.369643Z","shell.execute_reply.started":"2023-04-14T06:35:53.309039Z","shell.execute_reply":"2023-04-14T06:35:53.368527Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Fix seed","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed = 42\nseed_everything(seed)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T06:35:58.418819Z","iopub.execute_input":"2023-04-14T06:35:58.419253Z","iopub.status.idle":"2023-04-14T06:35:58.428645Z","shell.execute_reply.started":"2023-04-14T06:35:58.419218Z","shell.execute_reply":"2023-04-14T06:35:58.427119Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Define X_train, y_train, X_test","metadata":{}},{"cell_type":"code","source":"# Concatenate train and original dataframes, and prepare train and test sets\ndf_train = pd.concat([df_train, original])\nX_train = df_train.drop([f'{target_col}'],axis=1).reset_index(drop=True)\ny_train = df_train[f'{target_col}'].reset_index(drop=True)\nX_test = df_test.reset_index(drop=True)\n\nprint(f\"X_train shape :{X_train.shape} , y_train shape :{y_train.shape}\")\nprint(f\"X_test shape :{X_test.shape}\")\n\n# Delete the train and test dataframes to free up memory\ndel df_train, df_test","metadata":{"execution":{"iopub.status.busy":"2023-04-14T06:36:06.137921Z","iopub.execute_input":"2023-04-14T06:36:06.138375Z","iopub.status.idle":"2023-04-14T06:36:06.152962Z","shell.execute_reply.started":"2023-04-14T06:36:06.138337Z","shell.execute_reply":"2023-04-14T06:36:06.151747Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"X_train shape :(493, 7) , y_train shape :(493,)\nX_test shape :(276, 7)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## TabNet","metadata":{}},{"cell_type":"code","source":"# Learning Parameters\nbatch_size = 64 # 512\nmax_epochs = 500 # 500\npatience = 100\nnum_workers = os.cpu_count()\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2023-04-14T06:36:14.022349Z","iopub.execute_input":"2023-04-14T06:36:14.022782Z","iopub.status.idle":"2023-04-14T06:36:14.029014Z","shell.execute_reply.started":"2023-04-14T06:36:14.022745Z","shell.execute_reply":"2023-04-14T06:36:14.027564Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Define categorical features for categorical embeddings","metadata":{}},{"cell_type":"code","source":"def get_categorical_features(X_train, categorical_columns):\n    # Get the feature columns in X_train\n    feature_cols = [col for col in X_train.columns]\n    \n    # Create a dictionary to store the number of unique values for each categorical feature\n    categorical_dims = {}\n    for col in categorical_columns:\n        categorical_dims[col] = X_train[col].nunique()\n    \n    # Get the indices of the categorical features in the feature columns list\n    cat_idxs = [i for i, f in enumerate(feature_cols) if f in categorical_columns]\n    \n    # Get the number of unique values for each categorical feature\n    cat_dims = [categorical_dims[f] for i, f in enumerate(feature_cols) if f in categorical_columns]\n    \n    return feature_cols, cat_idxs, cat_dims\n\n# Get the feature columns, categorical feature indices, and number of unique values for each categorical feature\ncategorical_columns = ['is_generated']\nfeature_cols, cat_idxs, cat_dims = get_categorical_features(X_train, categorical_columns)\n\nprint('feature_cols:', feature_cols)\nprint('cat_idxs:', cat_idxs, ', cat_dims:', cat_dims)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T06:36:25.012204Z","iopub.execute_input":"2023-04-14T06:36:25.012611Z","iopub.status.idle":"2023-04-14T06:36:25.025427Z","shell.execute_reply.started":"2023-04-14T06:36:25.012578Z","shell.execute_reply":"2023-04-14T06:36:25.024122Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"feature_cols: ['gravity', 'ph', 'osmo', 'cond', 'urea', 'calc', 'is_generated']\ncat_idxs: [6] , cat_dims: [2]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a list comprehension to find columns in feature_cols that are not in categorical_columns\nnumerical_columns = [col for col in feature_cols if col not in categorical_columns]\n\n# Initialize StandardScaler\nscaler = StandardScaler()\n\n# Scale the numerical features in X_train and X_test using StandardScaler\nX_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\nX_test[numerical_columns] = scaler.transform(X_test[numerical_columns])","metadata":{"execution":{"iopub.status.busy":"2023-04-14T06:36:32.689145Z","iopub.execute_input":"2023-04-14T06:36:32.690022Z","iopub.status.idle":"2023-04-14T06:36:32.710557Z","shell.execute_reply.started":"2023-04-14T06:36:32.689918Z","shell.execute_reply":"2023-04-14T06:36:32.709321Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Split the training data into training and validation sets","metadata":{}},{"cell_type":"code","source":"def split_data(X, y, random_state, test_size=0.2, use_stratified_kfold=False, n_splits=6, n_repeats=5):\n    if use_stratified_kfold:\n        skf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n        for train_index, val_index in skf.split(X, y):\n            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n            yield X_train, X_val, y_train, y_val\n    else:\n        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=random_state)\n        yield X_train, X_val, y_train, y_val\n\nuse_stratified_kfold = True\nn_splits = 10 # 5\nn_repeats = 10\n\nfor X_train_, X_val, y_train_, y_val in split_data(X_train, y_train, random_state=seed, test_size=0.3, use_stratified_kfold=False, n_splits=n_splits, n_repeats=n_repeats):\n    print('Set data for Optuna')","metadata":{"execution":{"iopub.status.busy":"2023-04-14T06:37:04.157655Z","iopub.execute_input":"2023-04-14T06:37:04.158106Z","iopub.status.idle":"2023-04-14T06:37:04.231350Z","shell.execute_reply.started":"2023-04-14T06:37:04.158061Z","shell.execute_reply":"2023-04-14T06:37:04.230161Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Set data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\nSet data for Optuna\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_params(params):\n    optimizer_fn = torch.optim.Adam\n    optimizer_params = {\"lr\": 2e-2, \"weight_decay\": 1e-5}\n\n    scheduler_params = {\n        \"mode\": \"min\",\n        \"patience\": 5,\n        \"min_lr\": 1e-5,\n        \"factor\": 0.9\n    }\n    scheduler_fn = torch.optim.lr_scheduler.ReduceLROnPlateau\n\n    return {\n        \"n_d\": params['n_da'],\n        \"n_a\": params['n_da'],\n        \"n_steps\": params['n_steps'],\n        \"gamma\": params['gamma'],\n        \"lambda_sparse\": params['lambda_sparse'],\n        \"mask_type\": params['mask_type'],\n        \"n_shared\": params['n_shared'],\n        \"optimizer_fn\": optimizer_fn,\n        \"optimizer_params\": optimizer_params,\n        \"scheduler_fn\": scheduler_fn,\n        \"scheduler_params\": scheduler_params,\n        \"device_name\": device,\n        \"seed\": seed,\n        \"verbose\": 50\n    }","metadata":{"execution":{"iopub.status.busy":"2023-04-14T06:37:12.711315Z","iopub.execute_input":"2023-04-14T06:37:12.711743Z","iopub.status.idle":"2023-04-14T06:37:12.720339Z","shell.execute_reply.started":"2023-04-14T06:37:12.711701Z","shell.execute_reply":"2023-04-14T06:37:12.719236Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class TabNetOpt:\n    def __init__(self, batch_size, max_epochs, from_unsupervised=None):\n        self.max_epochs = max_epochs\n        self.batch_size = batch_size\n        self.from_unsupervised = from_unsupervised\n        \n    def pretrainer_objective(self, trial):\n        \"\"\"\n        Pre-trains a TabNet model and returns the best cost.\n        \"\"\"\n        params = self.get_params(trial)\n        pretrainer = TabNetPretrainer(**params)\n        pretrainer.fit(X_train=X_train.values, eval_set=[X_train.values],\n                       max_epochs=self.max_epochs, batch_size=self.batch_size) \n        return pretrainer.best_cost\n\n    def objective(self, trial):\n        \"\"\"\n        Trains a TabNet model and returns the score on the validation set.\n        \"\"\"\n        params = self.get_params(trial)\n        model = TabNetClassifier(**params)\n        params['cat_idxs'] = cat_idxs # Comment out when unsupervised\n        params['cat_dims'] = cat_dims # Comment out when unsupervised\n        params['cat_emb_dim'] = 1     # Comment out when unsupervised\n                \n        model.fit(X_train=X_train_.values, y_train=y_train_.values,\n                  eval_name=[\"train\", \"valid\"], eval_metric=[\"auc\"],\n                  eval_set=[(X_train_.values, y_train_.values), (X_val.values, y_val.values)],\n                  batch_size=self.batch_size,\n                  max_epochs=self.max_epochs,\n                  from_unsupervised=pretrainer)\n        score = roc_auc_score(y_val.values, model.predict(X_val.values))\n        return score\n\n    def get_params(self, trial):\n        \"\"\"\n        Returns a dictionary of hyperparameters for the TabNet model.\n        \"\"\"\n        mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n        n_da = trial.suggest_int(\"n_da\", 8, 64, step=8)\n        n_steps = trial.suggest_int(\"n_steps\", 1, 10, step=3)\n        gamma = trial.suggest_float(\"gamma\", 1.0, 2.0, step=0.2)\n        n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n        lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n\n        optimizer_fn = torch.optim.Adam\n        optimizer_params = {\"lr\": 2e-2, \"weight_decay\": 1e-5}\n\n        scheduler_params = {\n            \"mode\": \"min\",\n            \"patience\": 5,\n            \"min_lr\": 1e-5,\n            \"factor\": 0.9\n        }\n        scheduler_fn = torch.optim.lr_scheduler.ReduceLROnPlateau\n\n        return {\n            \"n_d\": n_da, \n            \"n_a\": n_da, \n            \"n_steps\": n_steps, \n            \"gamma\": gamma,\n            \"lambda_sparse\": lambda_sparse, \n            \"mask_type\": mask_type, \n            \"n_shared\": n_shared,\n            \"optimizer_fn\": optimizer_fn,\n            \"optimizer_params\": optimizer_params,\n            \"scheduler_fn\": scheduler_fn,\n            \"scheduler_params\": scheduler_params,\n            \"device_name\": device,\n            \"seed\": seed,\n            \"verbose\": 0\n        }","metadata":{"execution":{"iopub.status.busy":"2023-04-14T06:37:19.854935Z","iopub.execute_input":"2023-04-14T06:37:19.855329Z","iopub.status.idle":"2023-04-14T06:37:19.873086Z","shell.execute_reply.started":"2023-04-14T06:37:19.855299Z","shell.execute_reply":"2023-04-14T06:37:19.871798Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### TabNet Pretraining","metadata":{}},{"cell_type":"code","source":"# If you use optuna\nn_trials = 1\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(TabNetOpt(batch_size=batch_size, max_epochs=max_epochs).pretrainer_objective, n_trials=n_trials)\ntabnet_params = get_params(study.best_trial.params)\nprint(study.best_trial.params)\n\n# Default Parameters\ntabnet_params = {\n    'mask_type': 'entmax', 'n_da': 8, 'n_steps': 3, 'gamma': 1.3, 'n_shared': 2, 'lambda_sparse': 1e-3, 'seed': seed\n}\n\n# Parameters determined by Optuna\n# tabnet_params = {\n#     'mask_type': 'entmax', 'n_da': 16, 'n_steps': 1, 'gamma': 1.6, 'n_shared': 2, 'lambda_sparse': 0.00011313516037838907\n# }\ntabnet_params = get_params(tabnet_params)\n\nprint(tabnet_params)","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-04-14T06:37:24.678862Z","iopub.execute_input":"2023-04-14T06:37:24.679304Z","iopub.status.idle":"2023-04-14T06:37:57.469992Z","shell.execute_reply.started":"2023-04-14T06:37:24.679268Z","shell.execute_reply":"2023-04-14T06:37:57.468445Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\nEarly stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_unsup_loss_numpy = 0.5810099840164185\n{'mask_type': 'sparsemax', 'n_da': 24, 'n_steps': 10, 'gamma': 1.4, 'n_shared': 3, 'lambda_sparse': 1.0762103248895198e-06}\n{'n_d': 8, 'n_a': 8, 'n_steps': 3, 'gamma': 1.3, 'lambda_sparse': 0.001, 'mask_type': 'entmax', 'n_shared': 2, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.02, 'weight_decay': 1e-05}, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'mode': 'min', 'patience': 5, 'min_lr': 1e-05, 'factor': 0.9}, 'device_name': 'cpu', 'seed': 42, 'verbose': 50}\n","output_type":"stream"}]},{"cell_type":"code","source":"pretrainer = TabNetPretrainer(**tabnet_params)\nfit_params = {\n    \"X_train\": X_train.values,\n    \"eval_set\": [X_train.values],\n    \"max_epochs\": max_epochs,\n    \"patience\": patience, \n    \"batch_size\": batch_size, \n    \"virtual_batch_size\": batch_size // 2,\n    \"num_workers\": num_workers, \n    \"drop_last\": True\n}\n\npretrainer.fit(**fit_params)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-04-14T06:40:37.491916Z","iopub.execute_input":"2023-04-14T06:40:37.492379Z","iopub.status.idle":"2023-04-14T06:42:20.602388Z","shell.execute_reply.started":"2023-04-14T06:40:37.492344Z","shell.execute_reply":"2023-04-14T06:42:20.600829Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"epoch 0  | loss: 6.86515 | val_0_unsup_loss_numpy: 4.706910133361816|  0:00:00s\nepoch 50 | loss: 0.64709 | val_0_unsup_loss_numpy: 0.8163899779319763|  0:00:26s\nepoch 100| loss: 0.66841 | val_0_unsup_loss_numpy: 0.6899300217628479|  0:00:51s\nepoch 150| loss: 0.6695  | val_0_unsup_loss_numpy: 0.6429700255393982|  0:01:16s\nepoch 200| loss: 0.60449 | val_0_unsup_loss_numpy: 0.6250600218772888|  0:01:40s\n\nEarly stopping occurred at epoch 205 with best_epoch = 105 and best_val_0_unsup_loss_numpy = 0.571120023727417\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### TabNet Training","metadata":{}},{"cell_type":"code","source":"# If you use optuna\nn_trials = 500 # Optuna \nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(TabNetOpt(batch_size=batch_size, max_epochs=max_epochs, from_unsupervised=pretrainer).objective, n_trials=n_trials)\ntabnet_params = get_params(study.best_trial.params)\nprint(study.best_trial.params)\n\n# Default Parameters\n# tabnet_params = {\n#     'mask_type': 'entmax', 'n_da': 8, 'n_steps': 3, 'gamma': 1.3, 'n_shared': 2, 'lambda_sparse': 1e-3, 'seed': seed\n# }\n# tabnet_params = get_params(tabnet_params)\n\n# Parameters determined by Optuna\n# tabnet_params = {\n#     'mask_type': 'entmax', 'n_da': 32, 'n_steps': 1, 'gamma': 1.8, 'n_shared': 2, 'lambda_sparse': 9.234209012319759e-06\n# }\n# tabnet_params = get_params(tabnet_params)\n\nprint(tabnet_params)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-04-14T06:44:39.747025Z","iopub.execute_input":"2023-04-14T06:44:39.747564Z","iopub.status.idle":"2023-04-14T07:19:19.327789Z","shell.execute_reply.started":"2023-04-14T06:44:39.747525Z","shell.execute_reply":"2023-04-14T07:19:19.326528Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.7138\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.73401\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 13 with best_epoch = 3 and best_valid_auc = 0.70202\n\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_valid_auc = 0.73064\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_valid_auc = 0.73232\n\nEarly stopping occurred at epoch 13 with best_epoch = 3 and best_valid_auc = 0.72222\n\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_valid_auc = 0.72896\n\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_valid_auc = 0.73232\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71886\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71717\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76599\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.71212\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 21 with best_epoch = 11 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.73064\n\nEarly stopping occurred at epoch 24 with best_epoch = 14 and best_valid_auc = 0.71549\n\nEarly stopping occurred at epoch 38 with best_epoch = 28 and best_valid_auc = 0.76094\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71717\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.76768\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.69865\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71549\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71717\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77441\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.72559\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71549\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_valid_auc = 0.71717\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75758\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71717\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77273\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 33 with best_epoch = 23 and best_valid_auc = 0.70202\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71717\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.75253\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.77778\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71717\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76263\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71549\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76768\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77441\n\nEarly stopping occurred at epoch 25 with best_epoch = 15 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_valid_auc = 0.73232\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.77609\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.74579\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71549\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.75253\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.75758\n\nEarly stopping occurred at epoch 33 with best_epoch = 23 and best_valid_auc = 0.75758\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73232\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77104\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71549\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 30 with best_epoch = 20 and best_valid_auc = 0.76094\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76263\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77778\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.77778\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.8064\n\nEarly stopping occurred at epoch 31 with best_epoch = 21 and best_valid_auc = 0.75926\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71549\n\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_valid_auc = 0.71549\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76431\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73232\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73232\n\nEarly stopping occurred at epoch 25 with best_epoch = 15 and best_valid_auc = 0.76431\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71717\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75758\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.76599\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.78283\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77609\n\nEarly stopping occurred at epoch 31 with best_epoch = 21 and best_valid_auc = 0.75758\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.75253\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.73737\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.73906\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.78788\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71717\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73232\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.78956\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.74916\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76599\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 21 with best_epoch = 11 and best_valid_auc = 0.74916\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76431\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 30 with best_epoch = 20 and best_valid_auc = 0.77946\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77441\n\nEarly stopping occurred at epoch 24 with best_epoch = 14 and best_valid_auc = 0.72896\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73401\n\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_valid_auc = 0.73232\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.77609\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77946\n\nEarly stopping occurred at epoch 43 with best_epoch = 33 and best_valid_auc = 0.76768\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.76263\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 21 with best_epoch = 11 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 21 with best_epoch = 11 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.78114\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71549\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.79798\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76431\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75926\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.76431\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.77609\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.77104\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 33 with best_epoch = 23 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 32 with best_epoch = 22 and best_valid_auc = 0.7862\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76094\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.74916\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 34 with best_epoch = 24 and best_valid_auc = 0.74579\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.76431\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.74916\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.74916\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.74579\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77441\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77778\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76094\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.78114\n\nEarly stopping occurred at epoch 24 with best_epoch = 14 and best_valid_auc = 0.74579\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.78451\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 19 with best_epoch = 9 and best_valid_auc = 0.71717\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76431\n\nEarly stopping occurred at epoch 33 with best_epoch = 23 and best_valid_auc = 0.76263\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.78451\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.75758\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.78451\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.75926\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 35 with best_epoch = 25 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.75926\n\nEarly stopping occurred at epoch 38 with best_epoch = 28 and best_valid_auc = 0.77104\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.76094\n\nEarly stopping occurred at epoch 30 with best_epoch = 20 and best_valid_auc = 0.76263\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.79293\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76263\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76768\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.73737\n\nEarly stopping occurred at epoch 36 with best_epoch = 26 and best_valid_auc = 0.78283\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.76094\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76094\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.74579\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.77441\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 24 with best_epoch = 14 and best_valid_auc = 0.75758\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73232\n\nEarly stopping occurred at epoch 37 with best_epoch = 27 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 37 with best_epoch = 27 and best_valid_auc = 0.75758\n\nEarly stopping occurred at epoch 30 with best_epoch = 20 and best_valid_auc = 0.76768\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77946\n\nEarly stopping occurred at epoch 30 with best_epoch = 20 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.74916\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.74916\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.73906\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 21 with best_epoch = 11 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77273\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.75758\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.79125\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.75253\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_valid_auc = 0.73232\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 33 with best_epoch = 23 and best_valid_auc = 0.75758\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77104\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76263\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.73064\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.77778\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74579\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77778\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76094\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.76263\n\nEarly stopping occurred at epoch 21 with best_epoch = 11 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 30 with best_epoch = 20 and best_valid_auc = 0.74579\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.77609\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.79125\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.74916\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76768\n\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_valid_auc = 0.72896\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76431\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76263\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 13 with best_epoch = 3 and best_valid_auc = 0.70202\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77273\n\nEarly stopping occurred at epoch 21 with best_epoch = 11 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.75758\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77609\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.7862\n\nEarly stopping occurred at epoch 30 with best_epoch = 20 and best_valid_auc = 0.77609\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77609\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76599\n\nEarly stopping occurred at epoch 38 with best_epoch = 28 and best_valid_auc = 0.77104\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.77104\n\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_valid_auc = 0.7138\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.77778\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.76431\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.73906\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.78114\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 37 with best_epoch = 27 and best_valid_auc = 0.75926\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.75926\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.77946\n\nEarly stopping occurred at epoch 37 with best_epoch = 27 and best_valid_auc = 0.77104\n\nEarly stopping occurred at epoch 25 with best_epoch = 15 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77104\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76768\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.77441\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.77104\n\nEarly stopping occurred at epoch 33 with best_epoch = 23 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76768\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.76431\n\nEarly stopping occurred at epoch 21 with best_epoch = 11 and best_valid_auc = 0.73737\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.75253\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.76263\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71717\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.73401\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76094\n\nEarly stopping occurred at epoch 21 with best_epoch = 11 and best_valid_auc = 0.73737\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74916\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75926\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76263\n\nEarly stopping occurred at epoch 21 with best_epoch = 11 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.77946\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.75758\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75758\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.75926\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.74916\n\nEarly stopping occurred at epoch 19 with best_epoch = 9 and best_valid_auc = 0.70539\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 21 with best_epoch = 11 and best_valid_auc = 0.73737\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.78788\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.75926\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.75926\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 24 with best_epoch = 14 and best_valid_auc = 0.74579\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76599\n\nEarly stopping occurred at epoch 21 with best_epoch = 11 and best_valid_auc = 0.73401\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.74579\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.72727\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.75253\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 25 with best_epoch = 15 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71549\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77778\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 19 with best_epoch = 9 and best_valid_auc = 0.70707\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.76263\n\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_valid_auc = 0.6936\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.75926\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 36 with best_epoch = 26 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76094\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77273\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76599\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.78788\n\nEarly stopping occurred at epoch 24 with best_epoch = 14 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76599\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 25 with best_epoch = 15 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76431\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.77441\n\nEarly stopping occurred at epoch 37 with best_epoch = 27 and best_valid_auc = 0.77273\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.74916\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 24 with best_epoch = 14 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 24 with best_epoch = 14 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.77104\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71886\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.76094\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.77946\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76768\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.76263\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.7862\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.77946\n\nEarly stopping occurred at epoch 13 with best_epoch = 3 and best_valid_auc = 0.70202\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 34 with best_epoch = 24 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76599\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.71549\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.77946\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 34 with best_epoch = 24 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.77609\n\nEarly stopping occurred at epoch 24 with best_epoch = 14 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.70707\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.75926\n\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.75253\n\nEarly stopping occurred at epoch 24 with best_epoch = 14 and best_valid_auc = 0.74579\n\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_valid_auc = 0.73232\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 33 with best_epoch = 23 and best_valid_auc = 0.77946\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.77946\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.73906\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77104\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76263\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71717\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 25 with best_epoch = 15 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 33 with best_epoch = 23 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76599\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 13 with best_epoch = 3 and best_valid_auc = 0.70202\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.70539\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.76094\n\nEarly stopping occurred at epoch 37 with best_epoch = 27 and best_valid_auc = 0.76094\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.75926\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77609\n\nEarly stopping occurred at epoch 24 with best_epoch = 14 and best_valid_auc = 0.75253\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73232\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76599\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.77441\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.75253\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.77441\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.75758\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.72222\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.75926\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71717\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.76094\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.77273\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73232\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.74579\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.77273\n\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_valid_auc = 0.72896\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.73401\n\nEarly stopping occurred at epoch 60 with best_epoch = 50 and best_valid_auc = 0.76431\n\nEarly stopping occurred at epoch 25 with best_epoch = 15 and best_valid_auc = 0.75253\n\nEarly stopping occurred at epoch 23 with best_epoch = 13 and best_valid_auc = 0.74579\n\nEarly stopping occurred at epoch 21 with best_epoch = 11 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.7138\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.74916\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.78283\n\nEarly stopping occurred at epoch 29 with best_epoch = 19 and best_valid_auc = 0.76094\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 13 with best_epoch = 3 and best_valid_auc = 0.70202\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.78788\n\nEarly stopping occurred at epoch 13 with best_epoch = 3 and best_valid_auc = 0.70202\n\nEarly stopping occurred at epoch 21 with best_epoch = 11 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 13 with best_epoch = 3 and best_valid_auc = 0.72391\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.76431\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.70875\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74074\n\nEarly stopping occurred at epoch 25 with best_epoch = 15 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 12 with best_epoch = 2 and best_valid_auc = 0.72054\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.77946\n\nEarly stopping occurred at epoch 30 with best_epoch = 20 and best_valid_auc = 0.75084\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.76263\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.74747\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.78451\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.75421\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76768\n\nEarly stopping occurred at epoch 26 with best_epoch = 16 and best_valid_auc = 0.76599\n\nEarly stopping occurred at epoch 18 with best_epoch = 8 and best_valid_auc = 0.71717\n\nEarly stopping occurred at epoch 31 with best_epoch = 21 and best_valid_auc = 0.74916\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74242\n\nEarly stopping occurred at epoch 16 with best_epoch = 6 and best_valid_auc = 0.74411\n\nEarly stopping occurred at epoch 22 with best_epoch = 12 and best_valid_auc = 0.72727\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.76768\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.75589\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.73569\n\nEarly stopping occurred at epoch 28 with best_epoch = 18 and best_valid_auc = 0.76936\n\nEarly stopping occurred at epoch 27 with best_epoch = 17 and best_valid_auc = 0.76768\n{'mask_type': 'sparsemax', 'n_da': 8, 'n_steps': 10, 'gamma': 1.2, 'n_shared': 2, 'lambda_sparse': 5.950138521234092e-06}\n{'n_d': 8, 'n_a': 8, 'n_steps': 10, 'gamma': 1.2, 'lambda_sparse': 5.950138521234092e-06, 'mask_type': 'sparsemax', 'n_shared': 2, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'optimizer_params': {'lr': 0.02, 'weight_decay': 1e-05}, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'mode': 'min', 'patience': 5, 'min_lr': 1e-05, 'factor': 0.9}, 'device_name': 'cpu', 'seed': 42, 'verbose': 50}\n","output_type":"stream"}]},{"cell_type":"code","source":"tabnet_params['cat_idxs'] = cat_idxs # Comment out when unsupervised\ntabnet_params['cat_dims'] = cat_dims # Comment out when unsupervised\ntabnet_params['cat_emb_dim'] = 1     # Comment out when unsupervised\n\nmodel = TabNetClassifier(**tabnet_params)\n\ntabnet_models = []\nfor X_train_, X_val, y_train_, y_val in split_data(X_train, y_train, random_state=seed, test_size=0.2, use_stratified_kfold=use_stratified_kfold, n_splits=n_splits, n_repeats=n_repeats):\n    \n    fit_params = {\n        \"X_train\": X_train_.values, \n        \"y_train\": y_train_.values,\n        \"eval_set\": [\n            (X_train_.values, y_train_.values), \n            (X_val.values, y_val.values)\n        ],\n        \"eval_name\": [\"train\", \"valid\"],\n        \"eval_metric\": [\"auc\"],\n        \"batch_size\": batch_size,\n        \"max_epochs\": max_epochs,\n        \"patience\": patience,\n        \"drop_last\": True,\n        \"num_workers\": num_workers, \n        \"pin_memory\": True,\n        \"from_unsupervised\": pretrainer # comment out when Unsupervised\n    }\n    \n    model.fit(**fit_params)\n    tabnet_models.append(deepcopy(model))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-04-14T07:19:49.123997Z","iopub.execute_input":"2023-04-14T07:19:49.124411Z","iopub.status.idle":"2023-04-14T08:20:34.450413Z","shell.execute_reply.started":"2023-04-14T07:19:49.124379Z","shell.execute_reply":"2023-04-14T08:20:34.448185Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"epoch 0  | loss: 0.94544 | train_auc: 0.55634 | valid_auc: 0.68669 |  0:00:00s\nepoch 50 | loss: 0.37597 | train_auc: 0.92099 | valid_auc: 0.69156 |  0:00:33s\nepoch 100| loss: 0.34739 | train_auc: 0.95912 | valid_auc: 0.7013  |  0:01:05s\nepoch 150| loss: 0.29572 | train_auc: 0.97199 | valid_auc: 0.68506 |  0:01:36s\n\nEarly stopping occurred at epoch 170 with best_epoch = 70 and best_valid_auc = 0.74188\nepoch 0  | loss: 0.96502 | train_auc: 0.6335  | valid_auc: 0.65422 |  0:00:00s\nepoch 50 | loss: 0.38904 | train_auc: 0.92533 | valid_auc: 0.83442 |  0:00:32s\nepoch 100| loss: 0.32513 | train_auc: 0.96391 | valid_auc: 0.86039 |  0:01:04s\n\nEarly stopping occurred at epoch 104 with best_epoch = 4 and best_valid_auc = 0.88312\nepoch 0  | loss: 0.96221 | train_auc: 0.6448  | valid_auc: 0.76623 |  0:00:00s\nepoch 50 | loss: 0.4126  | train_auc: 0.90195 | valid_auc: 0.74838 |  0:00:32s\nepoch 100| loss: 0.36778 | train_auc: 0.94636 | valid_auc: 0.74351 |  0:01:03s\n\nEarly stopping occurred at epoch 102 with best_epoch = 2 and best_valid_auc = 0.84091\nepoch 0  | loss: 0.96189 | train_auc: 0.6657  | valid_auc: 0.63435 |  0:00:00s\nepoch 50 | loss: 0.41031 | train_auc: 0.92733 | valid_auc: 0.69388 |  0:00:32s\nepoch 100| loss: 0.31324 | train_auc: 0.9603  | valid_auc: 0.70748 |  0:01:04s\nepoch 150| loss: 0.28454 | train_auc: 0.96995 | valid_auc: 0.69728 |  0:01:36s\nepoch 200| loss: 0.29779 | train_auc: 0.97624 | valid_auc: 0.68707 |  0:02:08s\n\nEarly stopping occurred at epoch 212 with best_epoch = 112 and best_valid_auc = 0.77551\nepoch 0  | loss: 0.96634 | train_auc: 0.63765 | valid_auc: 0.65136 |  0:00:00s\nepoch 50 | loss: 0.40903 | train_auc: 0.90098 | valid_auc: 0.73639 |  0:00:32s\nepoch 100| loss: 0.37793 | train_auc: 0.93966 | valid_auc: 0.72959 |  0:01:04s\nepoch 150| loss: 0.30307 | train_auc: 0.95674 | valid_auc: 0.71429 |  0:01:36s\n\nEarly stopping occurred at epoch 151 with best_epoch = 51 and best_valid_auc = 0.7568\nepoch 0  | loss: 0.95787 | train_auc: 0.63861 | valid_auc: 0.66667 |  0:00:00s\nepoch 50 | loss: 0.38355 | train_auc: 0.91277 | valid_auc: 0.77609 |  0:00:32s\nepoch 100| loss: 0.31514 | train_auc: 0.9582  | valid_auc: 0.75758 |  0:01:04s\n\nEarly stopping occurred at epoch 107 with best_epoch = 7 and best_valid_auc = 0.867\nepoch 0  | loss: 0.95102 | train_auc: 0.65973 | valid_auc: 0.69024 |  0:00:00s\nepoch 50 | loss: 0.43715 | train_auc: 0.91131 | valid_auc: 0.61616 |  0:00:32s\nepoch 100| loss: 0.35342 | train_auc: 0.95065 | valid_auc: 0.55724 |  0:01:04s\n\nEarly stopping occurred at epoch 100 with best_epoch = 0 and best_valid_auc = 0.69024\nepoch 0  | loss: 0.94206 | train_auc: 0.67788 | valid_auc: 0.633   |  0:00:00s\nepoch 50 | loss: 0.39156 | train_auc: 0.92927 | valid_auc: 0.74242 |  0:00:33s\nepoch 100| loss: 0.31142 | train_auc: 0.96182 | valid_auc: 0.6835  |  0:01:05s\n\nEarly stopping occurred at epoch 148 with best_epoch = 48 and best_valid_auc = 0.78788\nepoch 0  | loss: 0.91025 | train_auc: 0.65673 | valid_auc: 0.66498 |  0:00:00s\nepoch 50 | loss: 0.3917  | train_auc: 0.91115 | valid_auc: 0.84007 |  0:00:32s\nepoch 100| loss: 0.36629 | train_auc: 0.94783 | valid_auc: 0.81481 |  0:01:04s\n\nEarly stopping occurred at epoch 139 with best_epoch = 39 and best_valid_auc = 0.88889\nepoch 0  | loss: 0.91574 | train_auc: 0.61305 | valid_auc: 0.69529 |  0:00:00s\nepoch 50 | loss: 0.39037 | train_auc: 0.90946 | valid_auc: 0.73064 |  0:00:32s\nepoch 100| loss: 0.33034 | train_auc: 0.94836 | valid_auc: 0.71717 |  0:01:04s\n\nEarly stopping occurred at epoch 106 with best_epoch = 6 and best_valid_auc = 0.8064\nepoch 0  | loss: 0.95509 | train_auc: 0.66614 | valid_auc: 0.60227 |  0:00:00s\nepoch 50 | loss: 0.41495 | train_auc: 0.92064 | valid_auc: 0.68669 |  0:00:32s\nepoch 100| loss: 0.33226 | train_auc: 0.94646 | valid_auc: 0.69968 |  0:01:03s\nepoch 150| loss: 0.2845  | train_auc: 0.96505 | valid_auc: 0.65909 |  0:01:35s\n\nEarly stopping occurred at epoch 196 with best_epoch = 96 and best_valid_auc = 0.75812\nepoch 0  | loss: 0.97707 | train_auc: 0.65984 | valid_auc: 0.57143 |  0:00:00s\nepoch 50 | loss: 0.40654 | train_auc: 0.92134 | valid_auc: 0.68994 |  0:00:31s\nepoch 100| loss: 0.36008 | train_auc: 0.95259 | valid_auc: 0.69156 |  0:01:02s\n\nEarly stopping occurred at epoch 106 with best_epoch = 6 and best_valid_auc = 0.80032\nepoch 0  | loss: 0.97159 | train_auc: 0.68254 | valid_auc: 0.67857 |  0:00:00s\nepoch 50 | loss: 0.40496 | train_auc: 0.92655 | valid_auc: 0.78734 |  0:00:32s\nepoch 100| loss: 0.42379 | train_auc: 0.96336 | valid_auc: 0.7711  |  0:01:04s\n\nEarly stopping occurred at epoch 135 with best_epoch = 35 and best_valid_auc = 0.82955\nepoch 0  | loss: 0.97109 | train_auc: 0.64202 | valid_auc: 0.66667 |  0:00:00s\nepoch 50 | loss: 0.39291 | train_auc: 0.91923 | valid_auc: 0.7398  |  0:00:32s\nepoch 100| loss: 0.33487 | train_auc: 0.95575 | valid_auc: 0.77551 |  0:01:04s\n\nEarly stopping occurred at epoch 105 with best_epoch = 5 and best_valid_auc = 0.78912\nepoch 0  | loss: 0.90712 | train_auc: 0.67124 | valid_auc: 0.7415  |  0:00:00s\nepoch 50 | loss: 0.46505 | train_auc: 0.894   | valid_auc: 0.85884 |  0:00:32s\nepoch 100| loss: 0.35805 | train_auc: 0.93958 | valid_auc: 0.82653 |  0:01:04s\nepoch 150| loss: 0.3256  | train_auc: 0.95386 | valid_auc: 0.84014 |  0:01:36s\n\nEarly stopping occurred at epoch 155 with best_epoch = 55 and best_valid_auc = 0.88095\nepoch 0  | loss: 0.98364 | train_auc: 0.67372 | valid_auc: 0.55219 |  0:00:00s\nepoch 50 | loss: 0.4141  | train_auc: 0.91306 | valid_auc: 0.67845 |  0:00:32s\nepoch 100| loss: 0.28154 | train_auc: 0.9719  | valid_auc: 0.69697 |  0:01:04s\n\nEarly stopping occurred at epoch 105 with best_epoch = 5 and best_valid_auc = 0.74242\nepoch 0  | loss: 0.94281 | train_auc: 0.65047 | valid_auc: 0.69697 |  0:00:00s\nepoch 50 | loss: 0.44548 | train_auc: 0.90678 | valid_auc: 0.82997 |  0:00:32s\nepoch 100| loss: 0.3256  | train_auc: 0.95215 | valid_auc: 0.80135 |  0:01:07s\n\nEarly stopping occurred at epoch 134 with best_epoch = 34 and best_valid_auc = 0.90404\nepoch 0  | loss: 0.97346 | train_auc: 0.5858  | valid_auc: 0.43771 |  0:00:00s\nepoch 50 | loss: 0.45242 | train_auc: 0.9008  | valid_auc: 0.70539 |  0:00:33s\nepoch 100| loss: 0.38312 | train_auc: 0.9346  | valid_auc: 0.67003 |  0:01:05s\nepoch 150| loss: 0.31981 | train_auc: 0.9589  | valid_auc: 0.64646 |  0:01:37s\n\nEarly stopping occurred at epoch 187 with best_epoch = 87 and best_valid_auc = 0.73737\nepoch 0  | loss: 0.91832 | train_auc: 0.68631 | valid_auc: 0.78451 |  0:00:00s\nepoch 50 | loss: 0.396   | train_auc: 0.90816 | valid_auc: 0.75926 |  0:00:32s\nepoch 100| loss: 0.41114 | train_auc: 0.94639 | valid_auc: 0.73569 |  0:01:04s\n\nEarly stopping occurred at epoch 112 with best_epoch = 12 and best_valid_auc = 0.85354\nepoch 0  | loss: 0.93299 | train_auc: 0.66623 | valid_auc: 0.69192 |  0:00:00s\nepoch 50 | loss: 0.41962 | train_auc: 0.89977 | valid_auc: 0.81818 |  0:00:32s\nepoch 100| loss: 0.33764 | train_auc: 0.94258 | valid_auc: 0.81145 |  0:01:04s\n\nEarly stopping occurred at epoch 128 with best_epoch = 28 and best_valid_auc = 0.867\nepoch 0  | loss: 0.93735 | train_auc: 0.67791 | valid_auc: 0.66396 |  0:00:00s\nepoch 50 | loss: 0.41624 | train_auc: 0.92109 | valid_auc: 0.75487 |  0:00:32s\nepoch 100| loss: 0.36448 | train_auc: 0.96774 | valid_auc: 0.68506 |  0:01:04s\n\nEarly stopping occurred at epoch 119 with best_epoch = 19 and best_valid_auc = 0.79545\nepoch 0  | loss: 0.94241 | train_auc: 0.70561 | valid_auc: 0.66883 |  0:00:00s\nepoch 50 | loss: 0.40828 | train_auc: 0.92266 | valid_auc: 0.74026 |  0:00:33s\nepoch 100| loss: 0.3599  | train_auc: 0.9552  | valid_auc: 0.78734 |  0:01:05s\n\nEarly stopping occurred at epoch 116 with best_epoch = 16 and best_valid_auc = 0.82143\nepoch 0  | loss: 0.95691 | train_auc: 0.63477 | valid_auc: 0.54383 |  0:00:00s\nepoch 50 | loss: 0.42669 | train_auc: 0.89629 | valid_auc: 0.70455 |  0:00:33s\nepoch 100| loss: 0.33312 | train_auc: 0.93646 | valid_auc: 0.72078 |  0:01:06s\n\nEarly stopping occurred at epoch 121 with best_epoch = 21 and best_valid_auc = 0.77273\nepoch 0  | loss: 0.96448 | train_auc: 0.65384 | valid_auc: 0.62755 |  0:00:00s\nepoch 50 | loss: 0.41857 | train_auc: 0.91899 | valid_auc: 0.76361 |  0:00:33s\nepoch 100| loss: 0.29853 | train_auc: 0.96186 | valid_auc: 0.77721 |  0:01:05s\n\nEarly stopping occurred at epoch 131 with best_epoch = 31 and best_valid_auc = 0.82653\nepoch 0  | loss: 0.97372 | train_auc: 0.67827 | valid_auc: 0.63946 |  0:00:00s\nepoch 50 | loss: 0.37637 | train_auc: 0.93045 | valid_auc: 0.76701 |  0:00:33s\nepoch 100| loss: 0.30203 | train_auc: 0.96736 | valid_auc: 0.73129 |  0:01:05s\n\nEarly stopping occurred at epoch 123 with best_epoch = 23 and best_valid_auc = 0.83844\nepoch 0  | loss: 0.91372 | train_auc: 0.6431  | valid_auc: 0.55724 |  0:00:00s\nepoch 50 | loss: 0.4528  | train_auc: 0.91244 | valid_auc: 0.72222 |  0:00:33s\nepoch 100| loss: 0.3299  | train_auc: 0.95188 | valid_auc: 0.72896 |  0:01:05s\nepoch 150| loss: 0.32676 | train_auc: 0.96894 | valid_auc: 0.74916 |  0:01:37s\n\nEarly stopping occurred at epoch 187 with best_epoch = 87 and best_valid_auc = 0.76768\nepoch 0  | loss: 0.97294 | train_auc: 0.65192 | valid_auc: 0.62626 |  0:00:00s\nepoch 50 | loss: 0.39135 | train_auc: 0.92236 | valid_auc: 0.70202 |  0:00:33s\nepoch 100| loss: 0.30981 | train_auc: 0.95871 | valid_auc: 0.62626 |  0:01:05s\n\nEarly stopping occurred at epoch 117 with best_epoch = 17 and best_valid_auc = 0.77946\nepoch 0  | loss: 0.94379 | train_auc: 0.68048 | valid_auc: 0.76768 |  0:00:00s\nepoch 50 | loss: 0.42397 | train_auc: 0.90981 | valid_auc: 0.84512 |  0:00:33s\nepoch 100| loss: 0.34498 | train_auc: 0.94785 | valid_auc: 0.82323 |  0:01:06s\nepoch 150| loss: 0.31566 | train_auc: 0.96262 | valid_auc: 0.81987 |  0:01:41s\n\nEarly stopping occurred at epoch 160 with best_epoch = 60 and best_valid_auc = 0.90741\nepoch 0  | loss: 0.91581 | train_auc: 0.57755 | valid_auc: 0.44276 |  0:00:00s\nepoch 50 | loss: 0.3819  | train_auc: 0.92102 | valid_auc: 0.84343 |  0:00:34s\nepoch 100| loss: 0.31569 | train_auc: 0.96334 | valid_auc: 0.7963  |  0:01:07s\n\nEarly stopping occurred at epoch 109 with best_epoch = 9 and best_valid_auc = 0.90404\nepoch 0  | loss: 0.94604 | train_auc: 0.60488 | valid_auc: 0.59428 |  0:00:00s\nepoch 50 | loss: 0.43791 | train_auc: 0.89036 | valid_auc: 0.82155 |  0:00:34s\nepoch 100| loss: 0.32965 | train_auc: 0.94791 | valid_auc: 0.84175 |  0:01:07s\nepoch 150| loss: 0.29061 | train_auc: 0.96536 | valid_auc: 0.81145 |  0:01:40s\n\nEarly stopping occurred at epoch 157 with best_epoch = 57 and best_valid_auc = 0.85185\nepoch 0  | loss: 0.97826 | train_auc: 0.63779 | valid_auc: 0.7711  |  0:00:00s\nepoch 50 | loss: 0.41227 | train_auc: 0.9049  | valid_auc: 0.80195 |  0:00:34s\nepoch 100| loss: 0.31399 | train_auc: 0.95276 | valid_auc: 0.77435 |  0:01:07s\n\nEarly stopping occurred at epoch 134 with best_epoch = 34 and best_valid_auc = 0.86688\nepoch 0  | loss: 0.95297 | train_auc: 0.63939 | valid_auc: 0.59253 |  0:00:00s\nepoch 50 | loss: 0.41128 | train_auc: 0.92047 | valid_auc: 0.72727 |  0:00:34s\nepoch 100| loss: 0.3524  | train_auc: 0.95317 | valid_auc: 0.65422 |  0:01:08s\n\nEarly stopping occurred at epoch 101 with best_epoch = 1 and best_valid_auc = 0.80682\nepoch 0  | loss: 0.9239  | train_auc: 0.709   | valid_auc: 0.66396 |  0:00:00s\nepoch 50 | loss: 0.41724 | train_auc: 0.91967 | valid_auc: 0.90097 |  0:00:34s\nepoch 100| loss: 0.33401 | train_auc: 0.95485 | valid_auc: 0.81169 |  0:01:07s\n\nEarly stopping occurred at epoch 134 with best_epoch = 34 and best_valid_auc = 0.93344\nepoch 0  | loss: 0.92073 | train_auc: 0.65246 | valid_auc: 0.7466  |  0:00:00s\nepoch 50 | loss: 0.46291 | train_auc: 0.8993  | valid_auc: 0.64116 |  0:00:34s\nepoch 100| loss: 0.35567 | train_auc: 0.94605 | valid_auc: 0.62415 |  0:01:06s\n\nEarly stopping occurred at epoch 102 with best_epoch = 2 and best_valid_auc = 0.76871\nepoch 0  | loss: 0.96105 | train_auc: 0.66389 | valid_auc: 0.78401 |  0:00:00s\nepoch 50 | loss: 0.44432 | train_auc: 0.90456 | valid_auc: 0.79592 |  0:00:33s\nepoch 100| loss: 0.36998 | train_auc: 0.93977 | valid_auc: 0.76361 |  0:01:07s\n\nEarly stopping occurred at epoch 134 with best_epoch = 34 and best_valid_auc = 0.81633\nepoch 0  | loss: 0.94379 | train_auc: 0.57347 | valid_auc: 0.63131 |  0:00:00s\nepoch 50 | loss: 0.43232 | train_auc: 0.89849 | valid_auc: 0.71549 |  0:00:34s\nepoch 100| loss: 0.32772 | train_auc: 0.95042 | valid_auc: 0.7138  |  0:01:08s\n\nEarly stopping occurred at epoch 116 with best_epoch = 16 and best_valid_auc = 0.76599\nepoch 0  | loss: 0.96066 | train_auc: 0.52432 | valid_auc: 0.4596  |  0:00:00s\nepoch 50 | loss: 0.38212 | train_auc: 0.92343 | valid_auc: 0.62458 |  0:00:34s\nepoch 100| loss: 0.31134 | train_auc: 0.96159 | valid_auc: 0.64141 |  0:01:06s\nepoch 150| loss: 0.26428 | train_auc: 0.97249 | valid_auc: 0.65825 |  0:01:40s\nepoch 200| loss: 0.27071 | train_auc: 0.97846 | valid_auc: 0.6431  |  0:02:13s\n\nEarly stopping occurred at epoch 231 with best_epoch = 131 and best_valid_auc = 0.6936\nepoch 0  | loss: 0.91757 | train_auc: 0.66381 | valid_auc: 0.633   |  0:00:00s\nepoch 50 | loss: 0.39877 | train_auc: 0.91148 | valid_auc: 0.62626 |  0:00:34s\nepoch 100| loss: 0.29155 | train_auc: 0.95075 | valid_auc: 0.6431  |  0:01:07s\n\nEarly stopping occurred at epoch 143 with best_epoch = 43 and best_valid_auc = 0.72896\nepoch 0  | loss: 0.99171 | train_auc: 0.65839 | valid_auc: 0.77441 |  0:00:00s\nepoch 50 | loss: 0.43344 | train_auc: 0.90081 | valid_auc: 0.71717 |  0:00:35s\nepoch 100| loss: 0.33807 | train_auc: 0.9634  | valid_auc: 0.72727 |  0:01:09s\n\nEarly stopping occurred at epoch 107 with best_epoch = 7 and best_valid_auc = 0.89226\nepoch 0  | loss: 0.96384 | train_auc: 0.67464 | valid_auc: 0.58586 |  0:00:00s\nepoch 50 | loss: 0.37191 | train_auc: 0.91886 | valid_auc: 0.73906 |  0:00:34s\nepoch 100| loss: 0.32859 | train_auc: 0.9549  | valid_auc: 0.72222 |  0:01:08s\n\nEarly stopping occurred at epoch 119 with best_epoch = 19 and best_valid_auc = 0.77946\nepoch 0  | loss: 0.95249 | train_auc: 0.69123 | valid_auc: 0.53896 |  0:00:00s\nepoch 50 | loss: 0.40682 | train_auc: 0.91597 | valid_auc: 0.65097 |  0:00:33s\nepoch 100| loss: 0.31914 | train_auc: 0.96553 | valid_auc: 0.6461  |  0:01:07s\n\nEarly stopping occurred at epoch 113 with best_epoch = 13 and best_valid_auc = 0.78247\nepoch 0  | loss: 0.92458 | train_auc: 0.69115 | valid_auc: 0.56981 |  0:00:00s\nepoch 50 | loss: 0.41069 | train_auc: 0.91338 | valid_auc: 0.73052 |  0:00:35s\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2904264504.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     }\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mtabnet_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_tabnet/abstract_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;31m# Apply predict epoch to all eval sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_tabnet/abstract_model.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSocketClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mSocketClient\u001b[0;34m(address)\u001b[0m\n\u001b[1;32m    616\u001b[0m     '''\n\u001b[1;32m    617\u001b[0m     \u001b[0mfamily\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maddress_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/socket.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, family, type, proto, fileno)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mproto\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mproto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io_refs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"#### Learning Progress","metadata":{}},{"cell_type":"code","source":"def plot_history(models):\n    fig, axs = plt.subplots(1, 3, figsize=(20, 6))\n    for j, param in enumerate(['loss', 'lr', 'valid_auc']):\n        for i, model in enumerate(models):\n            axs[j].plot(model.history[param], label=f'model {i}')\n        axs[j].set_title(param)\n        axs[j].set_xlabel('epoch')\n        axs[j].grid()\n        axs[j].legend()\n    plt.show()\n    \nplot_history(tabnet_models)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T12:48:54.342462Z","iopub.execute_input":"2023-04-07T12:48:54.34297Z","iopub.status.idle":"2023-04-07T12:48:55.16865Z","shell.execute_reply.started":"2023-04-07T12:48:54.342919Z","shell.execute_reply":"2023-04-07T12:48:55.167666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compare XGBoost, LightGBM, CatBoost, and RandomForest with TabNet","metadata":{}},{"cell_type":"markdown","source":"### XGBoost, LightGBM, CatBoost","metadata":{}},{"cell_type":"code","source":"# Hyperparameters\nn_estimators = 5000 # 5000\ndevice = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n\nxgb_params = {\n    'n_estimators': n_estimators,\n    'learning_rate': 0.05,\n    'max_depth': 7,\n    'subsample': 1.0,\n    'colsample_bytree': 1.0,\n    'n_jobs': -1,\n    'eval_metric': 'logloss',\n    'objective': 'binary:logistic',\n    'verbosity': 0,\n    'random_state': seed,\n}\nif device == 'gpu':\n    xgb_params['tree_method'] = 'gpu_hist'\n    xgb_params['predictor'] = 'gpu_predictor'\n\nlgb_params = {\n    'n_estimators': n_estimators,\n    'max_depth': 7,\n    'learning_rate': 0.05,\n    'subsample': 0.20,\n    'colsample_bytree': 0.56,\n    'reg_alpha': 0.25,\n    'reg_lambda': 5e-08,\n    'objective': 'binary',\n    'metric': 'binary_error',\n    'boosting_type': 'gbdt',\n    'device': device,\n    'random_state': seed\n}\n\ncb_params = {\n    'iterations': n_estimators,\n    'depth': 7,\n    'learning_rate': 0.1,\n    'l2_leaf_reg': 0.7,\n    'random_strength': 0.2,\n    'max_bin': 200,\n    'od_wait': 65,\n    'one_hot_max_size': 70,\n    'grow_policy': 'Depthwise',\n    'bootstrap_type': 'Bayesian',\n    'od_type': 'Iter',\n    'eval_metric': 'Logloss',\n    'loss_function': 'Logloss',\n    'task_type': device.upper(),\n    'random_state': seed\n}\n","metadata":{"execution":{"iopub.status.busy":"2023-04-07T12:48:55.172089Z","iopub.execute_input":"2023-04-07T12:48:55.172474Z","iopub.status.idle":"2023-04-07T12:48:55.183051Z","shell.execute_reply.started":"2023-04-07T12:48:55.17244Z","shell.execute_reply":"2023-04-07T12:48:55.181973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_classifier(classifier, X_train, y_train, X_val, y_val, classifier_params, early_stopping_rounds=300):\n    classifier = classifier(**classifier_params)\n    eval_set = [(X_val, y_val)]\n    classifier.fit(X_train, y_train, early_stopping_rounds=early_stopping_rounds, eval_set=eval_set, verbose=False)\n    val_preds = classifier.predict(X_val)\n    auc = roc_auc_score(y_val, val_preds)\n    return classifier, auc\n\nxgb_models, lgb_models, cb_models = [], [], []\nfor X_train_, X_val, y_train_, y_val in split_data(X_train, y_train, random_state=seed, test_size=0.2, use_stratified_kfold=use_stratified_kfold, n_splits=n_splits, n_repeats=n_repeats):\n    xgb_model, xgb_auc= train_classifier(xgb.XGBClassifier, X_train_, y_train_, X_val, y_val, xgb_params)\n    lgb_model, lgb_auc = train_classifier(lgb.LGBMClassifier, X_train_, y_train_, X_val, y_val, lgb_params)\n    cb_model, cb_auc = train_classifier(CatBoostClassifier, X_train_, y_train_, X_val, y_val, cb_params)\n    \n    xgb_models.append(deepcopy(xgb_model)), lgb_models.append(deepcopy(lgb_model)), cb_models.append(deepcopy(cb_model))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-04-07T12:48:55.184814Z","iopub.execute_input":"2023-04-07T12:48:55.18551Z","iopub.status.idle":"2023-04-07T12:49:08.959194Z","shell.execute_reply.started":"2023-04-07T12:48:55.185458Z","shell.execute_reply":"2023-04-07T12:49:08.958033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RandomForest","metadata":{}},{"cell_type":"code","source":"rf_params = {\n    'n_estimators': 1000,\n    'max_depth': 10,\n    'min_samples_leaf': 4,\n    'min_samples_split': 5\n}\n\n# Random Forest Classifier Model\nrf_model = RandomForestClassifier(random_state=seed, **rf_params)\nrf_models = []\nX_vals, y_vals = [], []\nfor X_train_, X_val, y_train_, y_val in split_data(X_train, y_train, random_state=seed, test_size=0.2, use_stratified_kfold=use_stratified_kfold, n_splits=n_splits, n_repeats=n_repeats):\n    rf_model.fit(X_train_, y_train_)\n    rf_models.append(deepcopy(rf_model))\n    X_vals.append(X_val), y_vals.append(y_val)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T12:49:08.960423Z","iopub.execute_input":"2023-04-07T12:49:08.962217Z","iopub.status.idle":"2023-04-07T12:49:17.959718Z","shell.execute_reply.started":"2023-04-07T12:49:08.96215Z","shell.execute_reply":"2023-04-07T12:49:17.958482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### AUC score for all models","metadata":{}},{"cell_type":"code","source":"def evaluate_ensemble(models, X_vals, y_vals):\n    ensemble_auc = []\n    for model, X_val, y_val in zip(models, X_vals, y_vals):\n        X_val, y_val = X_val.values, y_val.values\n        oof_pred = model.predict_proba(X_val)[:, 1].reshape(-1)\n        score = roc_auc_score(y_val, oof_pred)\n        ensemble_auc.append(score)\n    mean_score = np.mean(ensemble_auc)\n    std_score = np.std(ensemble_auc)\n    return f'{mean_score:.4f} ± {std_score:.4f}'","metadata":{"execution":{"iopub.status.busy":"2023-04-07T12:49:17.962597Z","iopub.execute_input":"2023-04-07T12:49:17.96312Z","iopub.status.idle":"2023-04-07T12:49:17.972039Z","shell.execute_reply.started":"2023-04-07T12:49:17.96307Z","shell.execute_reply":"2023-04-07T12:49:17.97075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('TabNet', evaluate_ensemble(tabnet_models, X_vals, y_vals))\nprint('XGBoost AUC score', evaluate_ensemble(xgb_models, X_vals, y_vals))\nprint('LightGBM AUC score', evaluate_ensemble(lgb_models, X_vals, y_vals))\nprint('CatBoost AUC score', evaluate_ensemble(cb_models, X_vals, y_vals))\nprint('RandomForest AUC score', evaluate_ensemble(rf_models, X_vals, y_vals))","metadata":{"execution":{"iopub.status.busy":"2023-04-07T12:49:17.973814Z","iopub.execute_input":"2023-04-07T12:49:17.974325Z","iopub.status.idle":"2023-04-07T12:49:18.731533Z","shell.execute_reply.started":"2023-04-07T12:49:17.97428Z","shell.execute_reply":"2023-04-07T12:49:18.730212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Feature Importance","metadata":{}},{"cell_type":"code","source":"def visualize_importance(models, feature_cols, title='TabNet'):\n    importances = []\n    feature_importance = pd.DataFrame()\n    for i, model in enumerate(models):\n        _df = pd.DataFrame()\n        _df[\"importance\"] = model.feature_importances_\n        _df[\"feature\"] = pd.Series(feature_cols)\n        _df[\"fold\"] = i\n        feature_importance = pd.concat([feature_importance, _df], axis=0, ignore_index=True)\n        \n    feature_importance = feature_importance.sort_values('importance', ascending=False)\n    plt.figure(figsize=(12, 4))\n    sns.barplot(x='importance', y='feature', data=feature_importance, color='skyblue', errorbar='sd')\n    plt.xlabel('Importance', fontsize=14)\n    plt.ylabel('Feature', fontsize=14)\n    plt.title(f'{title} Feature Importance', fontsize=18)\n    plt.grid(True, axis='x')\n    plt.show()\n\nvisualize_importance(tabnet_models, feature_cols, 'TabNet')\nvisualize_importance(xgb_models, list(X_train.columns), 'XGBoost')\nvisualize_importance(lgb_models, list(X_train.columns), 'LightGBM')\nvisualize_importance(cb_models, list(X_train.columns), 'CatBoost')\nvisualize_importance(rf_models, list(X_train.columns), 'RandomForest')","metadata":{"execution":{"iopub.status.busy":"2023-04-07T12:49:18.733123Z","iopub.execute_input":"2023-04-07T12:49:18.733509Z","iopub.status.idle":"2023-04-07T12:49:20.548887Z","shell.execute_reply.started":"2023-04-07T12:49:18.733476Z","shell.execute_reply":"2023-04-07T12:49:20.547667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Optuna Ensamble Model","metadata":{}},{"cell_type":"code","source":"class OptunaWeights:\n    def __init__(self, seed):\n        self.study = None\n        self.weights = None\n        self.seed = seed\n\n    def _objective(self, trial, y_true, y_preds):\n        # Define the weights for the predictions from each model\n        weights = [trial.suggest_float(f\"weight{n}\", 0, 1) for n in range(len(y_preds))]\n\n        # Calculate the weighted prediction\n        weighted_pred = np.average(np.array(y_preds).T, axis=1, weights=weights)\n\n        # Calculate the ROC AUC score for the weighted prediction\n        score = roc_auc_score(y_true, weighted_pred)\n        return score\n\n    def fit(self, y_true, y_preds, n_trials=2000):\n        optuna.logging.set_verbosity(optuna.logging.ERROR)\n        sampler = optuna.samplers.CmaEsSampler(seed=self.seed)\n        self.study = optuna.create_study(sampler=sampler, study_name=\"OptunaWeights\", direction='maximize')\n        objective_partial = partial(self._objective, y_true=y_true, y_preds=y_preds)\n        self.study.optimize(objective_partial, n_trials=n_trials)\n        self.weights = [self.study.best_params[f\"weight{n}\"] for n in range(len(y_preds))]\n\n    def predict(self, y_preds):\n        assert self.weights is not None, 'OptunaWeights error, must be fitted before predict'\n        weighted_pred = np.average(np.array(y_preds).T, axis=1, weights=self.weights)\n        return weighted_pred\n\n    def fit_predict(self, y_true, y_preds, n_trials=2000):\n        self.fit(y_true, y_preds, n_trials=n_trials)\n        return self.predict(y_preds)\n    \n    def weights(self):\n        return self.weights","metadata":{"execution":{"iopub.status.busy":"2023-04-07T12:49:20.550609Z","iopub.execute_input":"2023-04-07T12:49:20.550987Z","iopub.status.idle":"2023-04-07T12:49:20.563882Z","shell.execute_reply.started":"2023-04-07T12:49:20.550955Z","shell.execute_reply":"2023-04-07T12:49:20.562707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = np.array([tabnet_models, xgb_models, lgb_models, cb_models, rf_models]).T.tolist()\nnames = ['TabNet', 'XGBoost', 'LightGBM', 'CatBoost', 'RandomForest']\n\n# Initialize variables\ntest_pred = np.zeros(X_test.shape[0])\nzero_test_pred = np.zeros(X_test.shape[0])\nensemble_auc = []\nweights = []\n\n# Loop through the folds\ni = 0\nfor _model, (X_train_, X_val, y_train_, y_val) in zip(models, split_data(X_train, y_train, random_state=seed, test_size=0.2, use_stratified_kfold=use_stratified_kfold, n_splits=n_splits, n_repeats=n_repeats)):\n    val_probas, test_probas, zero_test_probas = [], [], []\n    for model in _model:\n        oof_pred = model.predict_proba(X_val.values)[:, 1]\n        test_proba = model.predict_proba(X_test.values)[:, 1]\n        zero_test_proba = model.predict_proba(X_test.values)[:, 0]\n        val_probas.append(oof_pred)\n        test_probas.append(test_proba)\n        zero_test_probas.append(zero_test_proba)\n        \n    # Use Optuna to find the best ensemble weights\n    optweights = OptunaWeights(seed=seed)\n    val_proba = optweights.fit_predict(y_val.values, val_probas)\n    score = roc_auc_score(y_val.values, val_proba)\n    print(f'[FOLD{i}] AUC score {score:.5f}')\n    ensemble_auc.append(score)\n    weights.append(optweights.weights)\n    \n    # Predict on the test set using the optimized ensemble weights\n    test_pred += optweights.predict(test_probas) / (n_splits * n_repeats)\n    zero_test_pred += optweights.predict(zero_test_probas) / (n_splits * n_repeats)\n    i += 1\n    \n# Calculate the mean AUC score of the ensemble\nmean_score = np.mean(ensemble_auc)\nstd_score = np.std(ensemble_auc)\nprint(f'Ensemble AUC score {mean_score:.5f} ± {std_score:.5f}')\n\n# Print the mean and standard deviation of the ensemble weights for each model\nprint('--- Model Weights ---')\nmean_weights = np.mean(weights, axis=0)\nstd_weights = np.std(weights, axis=0)\nfor name, mean_weight, std_weight in zip(names, mean_weights, std_weights):\n    print(f'{name} {mean_weight:.5f} ± {std_weight:.5f}')","metadata":{"execution":{"iopub.status.busy":"2023-04-07T12:49:20.565424Z","iopub.execute_input":"2023-04-07T12:49:20.56574Z","iopub.status.idle":"2023-04-07T12:49:31.151159Z","shell.execute_reply.started":"2023-04-07T12:49:20.565712Z","shell.execute_reply":"2023-04-07T12:49:31.14995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv(os.path.join(filepath, 'sample_submission.csv'))\nsub[f'{target_col}'] = test_pred\nsub.to_csv('submission.csv', index=False)\nsub.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T12:49:31.1531Z","iopub.execute_input":"2023-04-07T12:49:31.153957Z","iopub.status.idle":"2023-04-07T12:49:31.179373Z","shell.execute_reply.started":"2023-04-07T12:49:31.153911Z","shell.execute_reply":"2023-04-07T12:49:31.178063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(sub.target)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T12:49:31.181031Z","iopub.execute_input":"2023-04-07T12:49:31.181696Z","iopub.status.idle":"2023-04-07T12:49:31.457231Z","shell.execute_reply.started":"2023-04-07T12:49:31.181653Z","shell.execute_reply":"2023-04-07T12:49:31.455971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = [tabnet_models]\nnames = ['TabNet']\n\ndef save_submission(X_test, models, name):\n    print(name)\n    X_test = X_test.values\n    test_pred = np.zeros(X_test.shape[0])\n    for model in models:\n        test_pred += model.predict_proba(X_test)[:, 1].reshape(-1) / (n_splits * n_repeats)\n        \n    sub = pd.read_csv(os.path.join(filepath, 'sample_submission.csv'))\n    sub[f'{target_col}'] = test_pred\n    sub.to_csv('submission_tabnet.csv', index=False)\n    \nfor _model, name in zip(models, names):\n    save_submission(X_test, _model, name)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T12:49:31.459693Z","iopub.execute_input":"2023-04-07T12:49:31.460813Z","iopub.status.idle":"2023-04-07T12:49:31.586875Z","shell.execute_reply.started":"2023-04-07T12:49:31.460759Z","shell.execute_reply":"2023-04-07T12:49:31.585799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T12:49:31.588464Z","iopub.execute_input":"2023-04-07T12:49:31.589136Z","iopub.status.idle":"2023-04-07T12:49:31.600184Z","shell.execute_reply.started":"2023-04-07T12:49:31.589098Z","shell.execute_reply":"2023-04-07T12:49:31.598939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(sub.target)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T12:49:31.601775Z","iopub.execute_input":"2023-04-07T12:49:31.602464Z","iopub.status.idle":"2023-04-07T12:49:31.879349Z","shell.execute_reply.started":"2023-04-07T12:49:31.602428Z","shell.execute_reply":"2023-04-07T12:49:31.878181Z"},"trusted":true},"execution_count":null,"outputs":[]}]}